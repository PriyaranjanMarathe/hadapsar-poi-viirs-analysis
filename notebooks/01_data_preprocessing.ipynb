{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing - Foursquare POI and VIIRS Nighttime Lights\n",
    "\n",
    "This notebook demonstrates the data preprocessing pipeline for integrating Foursquare POI data with VIIRS nighttime lights data for Hadapsar, Pune analysis.\n",
    "\n",
    "## Objectives\n",
    "1. Load and preprocess Foursquare POI data\n",
    "2. Load and preprocess VIIRS nighttime lights data\n",
    "3. Filter data to Hadapsar region\n",
    "4. Prepare data for spatial integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import custom modules\n",
    "from preprocessing.foursquare_processor import FoursquareProcessor\n",
    "from preprocessing.viirs_processor import VIIRSProcessor\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Foursquare POI Data Preprocessing\n",
    "\n",
    "Let's start by processing the Foursquare POI data for the Hadapsar region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Foursquare processor\n",
    "foursquare_processor = FoursquareProcessor(data_dir=\"../data\")\n",
    "\n",
    "print(\"Foursquare processor initialized\")\n",
    "print(f\"Data directory: {foursquare_processor.data_dir}\")\n",
    "print(f\"Hadapsar bounds: {foursquare_processor.HADAPSAR_BOUNDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Foursquare POI data\n",
    "print(\"Starting Foursquare data processing...\")\n",
    "poi_output_file = foursquare_processor.process_foursquare_data()\n",
    "print(f\"\\nProcessing complete! Output saved to: {poi_output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine the processed POI data\n",
    "poi_gdf = gpd.read_file(poi_output_file)\n",
    "\n",
    "print(f\"Loaded POI data: {len(poi_gdf)} records\")\n",
    "print(f\"\\nColumns: {list(poi_gdf.columns)}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(poi_gdf.dtypes)\n",
    "\n",
    "# Display first few records\n",
    "print(f\"\\nFirst 5 records:\")\n",
    "display(poi_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize POI categories\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Category distribution\n",
    "category_counts = poi_gdf['category_group'].value_counts()\n",
    "ax1.pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "ax1.set_title('POI Category Distribution')\n",
    "\n",
    "# Spatial distribution\n",
    "poi_gdf.plot(ax=ax2, column='category_group', legend=True, markersize=20, alpha=0.7)\n",
    "ax2.set_title('Spatial Distribution of POIs in Hadapsar')\n",
    "ax2.set_xlabel('Longitude')\n",
    "ax2.set_ylabel('Latitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print category statistics\n",
    "print(\"\\nCategory Statistics:\")\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / len(poi_gdf)) * 100\n",
    "    print(f\"{category}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VIIRS Nighttime Lights Data Preprocessing\n",
    "\n",
    "Now let's process the VIIRS nighttime lights data for the same region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VIIRS processor\n",
    "viirs_processor = VIIRSProcessor(data_dir=\"../data\")\n",
    "\n",
    "print(\"VIIRS processor initialized\")\n",
    "print(f\"Data directory: {viirs_processor.data_dir}\")\n",
    "print(f\"Study area bounds: {viirs_processor.HADAPSAR_BOUNDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process VIIRS data\n",
    "print(\"Starting VIIRS data processing...\")\n",
    "viirs_output_file, viirs_stats = viirs_processor.process_viirs_data(year=2023)\n",
    "print(f\"\\nProcessing complete! Output saved to: {viirs_output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine VIIRS statistics\n",
    "print(\"VIIRS Data Statistics:\")\n",
    "print(\"=\" * 30)\n",
    "for key, value in viirs_stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize VIIRS data\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "# Load the clipped VIIRS raster\n",
    "with rasterio.open(viirs_output_file) as src:\n",
    "    viirs_data = src.read(1, masked=True)\n",
    "    viirs_transform = src.transform\n",
    "    viirs_crs = src.crs\n",
    "    viirs_bounds = src.bounds\n",
    "\n",
    "print(f\"VIIRS data shape: {viirs_data.shape}\")\n",
    "print(f\"VIIRS CRS: {viirs_crs}\")\n",
    "print(f\"VIIRS bounds: {viirs_bounds}\")\n",
    "\n",
    "# Visualize VIIRS data\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# VIIRS raster\n",
    "with rasterio.open(viirs_output_file) as src:\n",
    "    show(src, ax=ax1, cmap='viridis', title='VIIRS Nighttime Lights - Hadapsar')\n",
    "\n",
    "# Luminosity histogram\n",
    "valid_data = viirs_data[~viirs_data.mask]\n",
    "ax2.hist(valid_data, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax2.set_xlabel('Luminosity Value')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('VIIRS Luminosity Distribution')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment\n",
    "\n",
    "Let's assess the quality and coverage of both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POI data quality assessment\n",
    "print(\"POI Data Quality Assessment\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = poi_gdf.isnull().sum()\n",
    "print(\"Missing values:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Check coordinate validity\n",
    "lat_range = (poi_gdf.geometry.y.min(), poi_gdf.geometry.y.max())\n",
    "lon_range = (poi_gdf.geometry.x.min(), poi_gdf.geometry.x.max())\n",
    "print(f\"\\nLatitude range: {lat_range[0]:.6f} to {lat_range[1]:.6f}\")\n",
    "print(f\"Longitude range: {lon_range[0]:.6f} to {lon_range[1]:.6f}\")\n",
    "\n",
    "# Check for duplicate POIs\n",
    "duplicates = poi_gdf.duplicated(subset=['latitude', 'longitude']).sum()\n",
    "print(f\"\\nDuplicate locations: {duplicates}\")\n",
    "\n",
    "# Category distribution\n",
    "print(f\"\\nUnique categories: {poi_gdf['category_group'].nunique()}\")\n",
    "print(f\"Category distribution:\")\n",
    "print(poi_gdf['category_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIIRS data quality assessment\n",
    "print(\"VIIRS Data Quality Assessment\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Basic statistics\n",
    "valid_pixels = np.sum(~viirs_data.mask)\n",
    "total_pixels = viirs_data.size\n",
    "coverage_percent = (valid_pixels / total_pixels) * 100\n",
    "\n",
    "print(f\"Total pixels: {total_pixels:,}\")\n",
    "print(f\"Valid pixels: {valid_pixels:,}\")\n",
    "print(f\"Data coverage: {coverage_percent:.1f}%\")\n",
    "\n",
    "# Luminosity statistics\n",
    "valid_data = viirs_data[~viirs_data.mask]\n",
    "if len(valid_data) > 0:\n",
    "    print(f\"\\nLuminosity statistics:\")\n",
    "    print(f\"  Min: {valid_data.min():.4f}\")\n",
    "    print(f\"  Max: {valid_data.max():.4f}\")\n",
    "    print(f\"  Mean: {valid_data.mean():.4f}\")\n",
    "    print(f\"  Median: {np.median(valid_data):.4f}\")\n",
    "    print(f\"  Std: {valid_data.std():.4f}\")\n",
    "    \n",
    "    # Check for anomalous values\n",
    "    zero_values = np.sum(valid_data == 0)\n",
    "    negative_values = np.sum(valid_data < 0)\n",
    "    high_values = np.sum(valid_data > 100)  # Arbitrary threshold\n",
    "    \n",
    "    print(f\"\\nData distribution:\")\n",
    "    print(f\"  Zero values: {zero_values} ({zero_values/len(valid_data)*100:.1f}%)\")\n",
    "    print(f\"  Negative values: {negative_values}\")\n",
    "    print(f\"  High values (>100): {high_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial Coverage Analysis\n",
    "\n",
    "Let's analyze the spatial coverage and alignment of both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create overlay visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot VIIRS data as background\n",
    "with rasterio.open(viirs_output_file) as src:\n",
    "    show(src, ax=ax, cmap='viridis', alpha=0.7)\n",
    "\n",
    "# Overlay POI locations\n",
    "poi_gdf.plot(ax=ax, column='category_group', legend=True, \n",
    "            markersize=30, alpha=0.8, edgecolors='white', linewidth=0.5)\n",
    "\n",
    "ax.set_title('Spatial Overlay: POIs on VIIRS Nighttime Lights\\nHadapsar, Pune', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate spatial extent comparison\n",
    "poi_bounds = poi_gdf.total_bounds\n",
    "viirs_bounds_list = [viirs_bounds.left, viirs_bounds.bottom, viirs_bounds.right, viirs_bounds.top]\n",
    "\n",
    "print(\"Spatial Extent Comparison:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"POI bounds: {poi_bounds}\")\n",
    "print(f\"VIIRS bounds: {viirs_bounds_list}\")\n",
    "\n",
    "# Check if POI data falls within VIIRS coverage\n",
    "poi_within_viirs = (\n",
    "    poi_bounds[0] >= viirs_bounds.left and\n",
    "    poi_bounds[1] >= viirs_bounds.bottom and\n",
    "    poi_bounds[2] <= viirs_bounds.right and\n",
    "    poi_bounds[3] <= viirs_bounds.top\n",
    ")\n",
    "\n",
    "print(f\"\\nPOI data within VIIRS coverage: {poi_within_viirs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Next Steps\n",
    "\n",
    "Let's summarize the preprocessing results and prepare for data integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics\n",
    "summary = {\n",
    "    'POI Data': {\n",
    "        'total_records': len(poi_gdf),\n",
    "        'categories': poi_gdf['category_group'].nunique(),\n",
    "        'spatial_extent_km2': 'Hadapsar region',\n",
    "        'coordinate_system': str(poi_gdf.crs),\n",
    "        'data_quality': 'Good' if missing_values.sum() == 0 else 'Needs attention'\n",
    "    },\n",
    "    'VIIRS Data': {\n",
    "        'total_pixels': int(total_pixels),\n",
    "        'valid_pixels': int(valid_pixels),\n",
    "        'coverage_percent': f\"{coverage_percent:.1f}%\",\n",
    "        'coordinate_system': str(viirs_crs),\n",
    "        'luminosity_range': f\"{valid_data.min():.2f} to {valid_data.max():.2f}\",\n",
    "        'mean_luminosity': f\"{valid_data.mean():.2f}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for dataset, metrics in summary.items():\n",
    "    print(f\"\\n{dataset}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PREPROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nOutput Files:\")\n",
    "print(f\"- POI data: {poi_output_file}\")\n",
    "print(f\"- VIIRS data: {viirs_output_file}\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Run notebook 02_data_integration.ipynb for spatial integration\")\n",
    "print(\"2. Perform exploratory data analysis\")\n",
    "print(\"3. Create visualizations and dashboards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary to file\n",
    "import json\n",
    "\n",
    "# Save preprocessing summary\n",
    "summary_file = \"../data/processed/preprocessing_summary.json\"\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Preprocessing summary saved to: {summary_file}\")\n",
    "\n",
    "# Display file structure\n",
    "data_dir = Path(\"../data\")\n",
    "print(f\"\\nData directory structure:\")\n",
    "for item in sorted(data_dir.rglob(\"*\")):\n",
    "    if item.is_file():\n",
    "        relative_path = item.relative_to(data_dir.parent)\n",
    "        file_size = item.stat().st_size / 1024  # KB\n",
    "        print(f\"  {relative_path} ({file_size:.1f} KB)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}